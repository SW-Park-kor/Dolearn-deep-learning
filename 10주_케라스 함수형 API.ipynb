{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers\n",
    "\n",
    "input_tensor = Input(shape=(32,))\n",
    "dense = layers.Dense(32, activation='relu')\n",
    "\n",
    "output_tensor = dense(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_tensor, output_tensor)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 1s 2ms/step - loss: 11.8071\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.0665\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 12.8201\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 14.5011\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 16.6595\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19.2454\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 22.6456\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 26.9183\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 31.4102\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 36.2955\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 39.9670\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
    "score = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "\n",
    "embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 9s 133ms/step - loss: 6.2142 - acc: 0.0032\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 6.1976 - acc: 0.0650\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 6.1413 - acc: 0.0051\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 6.0411 - acc: 0.0092\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 5.9660 - acc: 0.0156\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 5.8794 - acc: 0.0169\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 5.8291 - acc: 0.0168\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 5.6862 - acc: 0.0224\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 5.6341 - acc: 0.0186\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 5.5582 - acc: 0.0246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25f090ebd60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
    "\n",
    "answers = np.random.randint(0, answer_vocabulary_size, size=num_samples)\n",
    "answers = to_categorical(answers)\n",
    "\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 375 7749 2735 ... 4483  294 4798]\n",
      " [9396 5069 6951 ... 6112 5855 4898]\n",
      " [9572  136 3589 ... 6841 8066 5258]\n",
      " ...\n",
      " [3072 3442 1576 ... 2562 6000 7690]\n",
      " [6822 8342 3829 ... 2488 4980 1315]\n",
      " [6461 2344 2800 ... 8843  533 7952]]\n",
      "[[7282 4699   57 ... 1195 6023 8900]\n",
      " [7112 2639 9492 ... 7046 3793 6239]\n",
      " [4533 8846 4675 ... 4840 1345  957]\n",
      " ...\n",
      " [9580 2501  959 ... 1832 4574 6605]\n",
      " [5866 1949 9341 ... 8026 2374 3874]\n",
      " [6278 9373 1658 ... 7046 9093 8955]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "print(question)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "posts (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 256)    12800000    posts[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 128)    163968      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, None, 128)    0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 256)    164096      max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 256)    327936      conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 256)    0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 256)    327936      max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 256)    327936      conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 256)          0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          32896       global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            129         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 10)           1290        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 1)            129         dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,146,316\n",
      "Trainable params: 14,146,316\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import Input \n",
    "from keras.models import Model \n",
    "\n",
    "vocabulary_size = 50000 \n",
    "num_income_groups = 10 \n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(vocabulary_size,256)(posts_input)\n",
    "\n",
    "x = layers.Conv1D(128, 5, activation='relu', padding='same')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x) \n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x) \n",
    "\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax',name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "model = Model(posts_input,[age_prediction, income_prediction, gender_prediction])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 12s 506ms/step - loss: 2412.8521 - age_loss: 2405.2502 - income_loss: 6.5868 - gender_loss: 1.0149\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 8s 501ms/step - loss: 628.5668 - age_loss: 623.1308 - income_loss: 4.7272 - gender_loss: 0.7088\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 8s 518ms/step - loss: 570.8103 - age_loss: 567.6190 - income_loss: 2.5024 - gender_loss: 0.6890\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 8s 483ms/step - loss: 343.6989 - age_loss: 340.6554 - income_loss: 2.3262 - gender_loss: 0.7173\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 8s 481ms/step - loss: 445.5416 - age_loss: 442.5123 - income_loss: 2.3228 - gender_loss: 0.7066\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 8s 485ms/step - loss: 255.2176 - age_loss: 252.2418 - income_loss: 2.2807 - gender_loss: 0.6951\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 8s 499ms/step - loss: 358.6709 - age_loss: 355.7088 - income_loss: 2.2671 - gender_loss: 0.6949\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 8s 507ms/step - loss: 234.4180 - age_loss: 231.4203 - income_loss: 2.2872 - gender_loss: 0.7105\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 8s 496ms/step - loss: 474.0575 - age_loss: 471.0988 - income_loss: 2.2536 - gender_loss: 0.7052\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 8s 468ms/step - loss: 228.4260 - age_loss: 225.4428 - income_loss: 2.2704 - gender_loss: 0.7128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25f095c6580>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "num_samples = 1000 \n",
    "max_length = 100 \n",
    "\n",
    "posts = np.random.randint(1, vocabulary_size, size=(num_samples, max_length))\n",
    "age_targets = np.random.randint(0, 100, size=(num_samples,1))\n",
    "income_targets = np.random.randint(1, num_income_groups, size=(num_samples,1))\n",
    "income_targets = keras.utils.to_categorical(income_targets,num_income_groups)\n",
    "gender_targets = np.random.randint(0, 2, size=(num_samples,1))\n",
    "\n",
    "model.fit(posts, [age_targets, income_targets, gender_targets], epochs=10, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 4ms/step - loss: 0.6980 - acc: 0.5149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25f11bbfca0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "num_samples = 100\n",
    "num_symbols = 2\n",
    "\n",
    "lstm = layers.LSTM(32)\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "right_input = Input(shape=(None, 128))\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
    "\n",
    "left_data = np.random.randint(0, num_symbols, size=(num_samples,1,128))\n",
    "right_data = np.random.randint(0, num_symbols, size=(num_samples,1,128))\n",
    "matching_list = [np.random.randint(0, num_symbols) for _ in range(num_samples)]\n",
    "targets = np.array(matching_list)\n",
    "\n",
    "model.fit([left_data, right_data], targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#케라스 콜백 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a270b40f5339>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_acc',\n",
    "        patience=1,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='my_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_onpy=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(x, y, epochs=10, batch_size=32, callbacks=callbacks_list, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "  keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss'\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "  )\n",
    "]\n",
    "\n",
    "model.fit(x, y,epochs=10, batch_size=32, callbacks=callbacks_list,validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "class ActivationLogger(keras.callbacks.Callback):\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        layer_outputs = [layer.output for layer in model.layers]\n",
    "        self.activations_model = keras.models.Model(model.input,\n",
    "        layer_outputs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.validation_data is None:\n",
    "              raise RuntimeError('Requires validation_data.')\n",
    "      \n",
    "        validation_sample = self.validation_data[0][0:1]\n",
    "        activations = self.activations_model.predict(validation_sample)\n",
    "        f = open('activations_at_epoch_' + str(epoch) + '.npz', 'w')\n",
    "        np.savez(f, activations)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
